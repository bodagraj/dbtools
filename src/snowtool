#!/usr/bin/python3
#import multiprocessing as mp
import logging
import threading
import time
from logging.handlers import RotatingFileHandler
import os
import subprocess
import shlex
import tempfile
import pprint
import json
import sys
import argparse
import teradatasql
import pandas as pd
import sqlalchemy
import warnings



#print("Number of processors: ", mp.cpu_count())


def setup_logging(arg):
	
	"""
	Setup a default log file to /tmp/filename.log
	logfile will be rotated if it crosses 500MB upto maximum of 4 recent logs
	Format prints as follows
	2022-01-27 02:16:09,713 - [DEBUG] - [Thread-1] - root - (snowtool.py).monitor_worker(12) - Hi from myfunc
	2022-01-27 02:16:09,714 - [DEBUG] - [MainThread] - root - (snowtool.py).main(38) - Hello from main
	"""
	
	prog_name = os.path.basename(os.path.realpath(__file__))
	fname = tempfile.gettempdir() +'/'+ prog_name + '.log'
	logging.basicConfig(
		level=logging.DEBUG,
		format="%(asctime)s - [%(levelname)s] - [%(threadName)s] - %(name)s - (%(filename)s).%(funcName)s(%(lineno)d) - %(message)s",
		handlers=[RotatingFileHandler(filename=fname,mode='w', maxBytes=512000, backupCount=4)]
	)
	print(" * check detailed progress in [",fname,"] hit cntrl+c to terminate the program")

		
def main(arg):

	"""
	Multi threaded program it uses multithreading rater than multiprocessing, as the logic of this progra is not compute intesnive.
	"""
	my_arg = pprint.pformat(arg)
	logging.info("input arguments are : \n"+my_arg)

	try:
		logging.debug('Starting main program...')
		
		if 'copy_data' in arg['action'].keys():
			copy_data_args = arg['action']['copy_data']
			handle_copy_data(copy_data_args)
		else:
			msg = "input configuration doesn't defined any action, exiting!"
			print(msg)
			logging.critical(msg)	
			sys.exit(-1)
	except KeyboardInterrupt:
		info['stop'] = True
		logging.critical("keyboard inturrupt recieved terminating the program...",info)
		sys.exit(-1)
	except Exception as e:
		logging.critical(e)
		print("Oops!,", e.__class__, "occurred.")
		sys.exit(-1)
	
	## check final status
	msg = " * Program completed, check logs for more details"
	logging.info(msg)
	print(msg)
	sys.exit(0)

def handle_copy_data(arg):
	logging.info('Processing action=copy_data')
	threads = []
	### monitor process
	info = {'stop': False}
	thread = threading.Thread(target=monitor_worker, args=(arg,))
	thread.start()
	threads.append(thread)
	
	### process source
	thread_source = threading.Thread(target=process_source, args=(arg,))
	thread_source.start()
	threads.append(thread_source)
	
	# join all threads
	for t in threads:
		t.join()

def process_source(arg):
	my_arg = pprint.pformat(arg)
	logging.info("input arguments are : \n"+my_arg)
	logging.debug('connecting to source:'+arg['source']['dbhost'])
	connect = teradata_connect(arg['source'])
	source_db = arg['source']['dbname']
	#Reading query to df
	tab_args = {
		"sql" : f"""
			select
				trim(t.DatabaseName) as DatabaseName,
				trim(t.TableName) as TableName,
				trim(t.TableKind) as TableKind,
				trim(c.ColumnName) as ColumnName,
				trim(c.ColumnType) as ColumnType,
				trim(c.ColumnLength) as ColumnLength,
				trim(Nullable) as Nullable,
				trim(DecimalTotalDigits) DecimalTotalDigits,
				trim(DecimalFractionalDigits) DecimalFractionalDigits,
				trim(ColumnId) ColumnId
			from
				dbc.tables t inner join dbc.columns c on t.TableName=c.TableName and t.DatabaseName=c.DatabaseName
			where t.DatabaseName='{source_db}'
			""",
		"connect" : connect
	}
	table_dic = teradata_get_table_details(tab_args)
	print(table_dic)
	
	
	status = ''
	return status

def teradata_get_table_details(arg):
	table_dic = {}
	df = None
	query = arg['sql']
	connect = arg['connect']
	
	logging.debug('executing query:'+query)
	try:
		warnings.filterwarnings("ignore")
		df = pd.read_sql(query,connect)
	except Exception as e:
		logging.critical(e)
		sys.exit(-1)
	
	df = df.reset_index()  # make sure indexes pair with number of rows
	for index, row in df.iterrows():
		table_name = row['DatabaseName']+'.'+row['TableName']
		table_kind = row['TableKind']
		table_dic[table_name] = {'table_kind' : table_kind}
	
	return table_dic
	
	
def teradata_connect(arg):
	
	dbhost = arg['dbhost']
	dbuser = arg['user']
	dbpass = arg['password']
	
	conn = None
	
	try:
		conn = teradatasql.connect(host=dbhost, user=dbuser, password=dbpass)
		#data = pd.read_sql('select top 5 * from dbc.tables;', conn)
	except Exception as e:
		logging.critical(e)
		sys.exit(-1)
	
	msg = "Successfully made connection to "+dbhost
	logging.info(msg)
	return conn

def monitor_worker(arg):
	
	'''
	Monitor all threads/processors
	'''
	my_arg = pprint.pformat(arg)
	logging.info("input arguments are : \n"+my_arg)
	
	cmd_args = {
				'cmd' : 'ping -c 4 python.org'
				}
	
	status = None
	try:
		status = execute_command(cmd_args)
	except Exception as ex:
		json_string = json.dumps(status)
		logging.critical(ex)
		logging.critical(json_string+"\nThread failure, exiting...")
		sys.exit()
	#print(status['return_code'])


def execute_command(arg):

	"""
	Takes command and arguments in a dictionary and returns the status back
	"""
	cmd = arg['cmd']
	args = shlex.split(cmd)
	#my_arg = pprint.pformat(arg)
	json_string = json.dumps(arg)
	logging.debug("Executing with the following arguments:\n"+json_string)
	
	out = ''
	err = ''
	return_code = -1
	process = None
	
	try:
		process = subprocess.Popen(
			args, 
			stdin=subprocess.PIPE,
			stdout=subprocess.PIPE,
			stderr=subprocess.PIPE,
			text=True,
			universal_newlines=True,
		)
	except FileNotFoundError as e:
		#err = "".join(process.stderr.readlines())
		err = 'Command failed, exception returned:'+format(e)+',exiting....'
		logging.critical(err)
		#sys.exit()
	except:
		logging.critical("Error, Exception not handled , exiting...")
		sys.exit(-1)
	
	if process is not None:
		return_code = process.poll()
	else:
		logging.critical('processing failed, preparing to exit...')
		sys.exit(-1)
		
	
	while True:
		#output = process.stdout.readline()
		#logging.info(output.strip())
		# Do something else, grepping et.c....
		return_code = process.poll()
		
		if return_code is not None:
			logging.info('RETURN CODE:'+ str(return_code))
			# Process has finished, read rest of the output
			out = "".join(process.stdout.readlines())
			err = "".join(process.stderr.readlines())
			logging.info("Command returned\n"+"\nout ==> "+out)
			if err != '':
				print("ERROR ==> "+err)
			
			if return_code != 0:
				logging.critical('Command failed, please check messages above')
			
			break
	
	return {
		'output' : out+"\n"+err,
		'return_code' : return_code
	}

def parse_inputs():
	parser = argparse.ArgumentParser(
		description='Tool to load data from teradata to snowflake using multithreading')
	parser.add_argument('-config', action='store', type=str, required=True,
		help='snowtool Config file path')
		
	#args = parser.parse_args()
	args = vars(parser.parse_args())
	config_file = args['config']
	
	f = open(config_file)
	json_args = json.load(f)
	f.close()
	return json_args
	

if __name__ == '__main__':
	input_args = parse_inputs()
	setup_logging(input_args)
	main(input_args)
